# -*- coding: utf-8 -*-
"""Client-Facing Index Scoring Prototype.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BzWO5iSXwV0IvmIYoHTGrAlYTZ9iB3R7

# Index Scoring
This notebook outlines how to create a heat map that represents a composite index score. 


# Methodology
Composite index scoring is typically used by understanding how a student is perfoming against their peers. [Example](https://medium.com/analytics-vidhya/the-factor-analysis-for-constructing-a-composite-index-2496686fc54c). GIS experts use this to have visuals by geography or trade area ranking and answer questions into things related to site selection, site planning, or targeting consumers.

# What is a Z-Score
Simply put, a z-score (also called a standard score or an index score) reveals how far above or below average this instance is compared to it's peers. But more technically itâ€™s a measure of how many standard deviations below or above the mean a raw score is. More info [here](https://www.statisticshowto.com/probability-and-statistics/z-score/).
"""

import pandas as pd
!pip install geopandas
import geopandas as gpd

import numpy as np 
from sklearn import preprocessing

# # Pandas Read CSV
df = pd.read_csv("/content/node_composite_score3.csv", encoding_errors='ignore')


# # you could drop rows where our variables all = 0 it will create holes in our final gdf
df2 = df[['FIPS','Within_DTPlus_TTA','Income_Attainment', 'Edu_Attainment', 'Eth_Hispanic_CrYr','geometry']]

df3 = df[['FIPS','Income_Attainment', 'Edu_Attainment', 'Eth_Hispanic_CrYr']]


# round our values
df3.head(3)

"""### Standardizing Each Variable

This is important if you have to compare apples to oranges. Meaning, you might have a vairiable that's a percentage while another variable that's a raw count. 


### Why -3 to 3?
Defining the ranges in the minmax scaler from -3 to 3. 
I want to have enough variance and a typical 0-1 variance is a bit tight.
> In most large data sets, 99% of values have a Z-score between -3 and 3, meaning they lie within three standard deviations above or below the mean.
- [Investopia Team](https://www.investopedia.com/ask/answers/021115/what-difference-between-standard-deviation-and-z-score.asp)



"""

## define the scaler
## scaler is set to a range of -3 to 3 
scaler = preprocessing.MinMaxScaler(feature_range=(-3, 3), copy=True, clip=False)


## Testing with a seperate df to keep my sanity
df_scaled = df3.copy()

## Run the minmax scaler on our target variables
df_scaled[['Income_Attainment', 'Edu_Attainment','Eth_Hispanic_CrYr']] = scaler.fit_transform(df_scaled[['Eth_Hispanic_CrYr', 'Income_Attainment','Edu_Attainment']]).round(2)

## rename our columns to a human-friendly readable column
df_scaled.rename(columns = {'Income_Attainment':'Income_Attainment_score', 'Edu_Attainment':'Edu_Attainment_score', 'Eth_Hispanic_CrYr':'Eth Hispanic CrYr_score'}, inplace = True)

 
df_scaled = df_scaled[['FIPS', 'Income_Attainment_score','Edu_Attainment_score','Eth Hispanic CrYr_score' ]]
df_scaled

"""### Weighting

Weighting would be applied here. It's as simple as multiplying each cap with the weight value.

example: if the weight is 1/2 important - we would multiple the variable by 0.5
"""



"""### Composite Variable
Here's the magic number - it's really simple. Just add each column into one.

### Final Z Score
A Z-score is a numerical measurement that describes a value's relationship to the mean of a group of values. Z-score is measured in terms of standard deviations from the mean. If a Z-score is 100, it indicates that the data point's score is identical to the mean score


"""

## Create a composite score
df_scaled['Composite_Score'] = df_scaled[["Income_Attainment_score" , "Edu_Attainment_score",'Eth Hispanic CrYr_score']].sum(axis = 1)

df_scaled[['Composite_Score']] = preprocessing.scale(df_scaled[['Composite_Score']])


df_scaled

df_scaled[['Composite_Score']] = scaler.fit_transform(df_scaled[['Composite_Score']]).round(2)

standscaler = preprocessing.StandardScaler()


## Define the max of the composite score
max = df_scaled['Composite_Score'].max()


## Calculate the index, results will yield a final score from 0 to 200 (100 = average)
df_scaled[['Index_Score']] = df_scaled[['Composite_Score']].apply(lambda x: (1 + (x/max))*100).round(1)
df_scaled[["Income_Attainment_score" , "Edu_Attainment_score",'Eth Hispanic CrYr_score']] = df_scaled[["Income_Attainment_score" , "Edu_Attainment_score",'Eth Hispanic CrYr_score']].apply(lambda x: (1 + (x/3))*100).round(1)

## appending our score to our OG dataframe
finaldf = pd.merge(df2, df_scaled[["FIPS", "Income_Attainment_score","Edu_Attainment_score","Eth Hispanic CrYr_score","Composite_Score","Index_Score"]], on='FIPS', how='left')

## Rank field can be helpful if we were exploring geographies with less ambigous names (example top 25 CBSAs and exploring the results through table view)
finaldf['Rank'] = finaldf['Composite_Score'].rank(ascending = False)
finaldf = finaldf.sort_values(by = 'Rank').reset_index()


finaldf.head(25)

## export if you wanna poke around
finaldf.to_csv('node_composite_score.csv')

